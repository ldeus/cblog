# Training-WWW-Robots
## 题目
In this little training challenge, you are going to learn about the [Robots_exclusion_standard](http://en.wikipedia.org/wiki/Robots_exclusion_standard "Robots_exclusion_standard").  
The robots.txt file is used by web crawlers to check if they are allowed to crawl and index your website or only parts of it.  
Sometimes these files reveal the directory structure instead protecting the content from being crawled.  
  
Enjoy!

## 思路
看题目是要去看网站根目录下的`robots.txt`文件，该文件为建议web爬虫用来检测是否允许其爬取你的网站内容的。打开其内容为：  
```html
User-agent: *
Disallow: /fl0g.php


User-agent: Yandex
Disallow: *
```
发现根目录下存在`fl0g.php`。打开发现`fl0g.php`为`cyberpeace{7f9073002a632301605313e6a08a7f1b}`
## 总结
本题为掌握robots.txt的意义及位置。便于获取部分目录结构内容。
